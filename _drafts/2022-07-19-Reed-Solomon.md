---
layout: post
title: Reed-Solomon Info
date:  2022-07-19 00:00:00 -1000
categories:
---

# Introduction

I've always been intimidated by coding techniques: encryption and decryption, hashing operations,
error correction codes, and even compression and decompression techniques. It's not that I
didn't know what they do, and there have been cases where I've even worked with them 
professionally, but I felt that I never quite understood the basics, the theory, on
which these techniques are based.

One coding technique that I found particularly obscure was Reed-Solomon-based forward
error correction. It's not for lack of material on the web, because it's covered in many
college-level courses on coding and signal processing techniques. But a lot of that material
assumes a certain theoretical base and builds on that. They'll start with Galois
Fields and polynomials, throw a bunch of mathematical formulas at you, and you're left
with very little intuitive understanding.

That changed when stumbled into this 
[Introduction to Reed-Solomon](https://innovation.vivint.com/introduction-to-reed-solomon-bc264d0794f8)
article. It explains how polynomials and polynomial evaluation at certain points create a way to
create a code with redundancy, and how to recover the original message back from it. The article
is excellent, and it makes a lot of what I'll be covering below unnecessary. Because a major
part of what follows will be a recreation of that material... but dumbed down even more, and with
more examples too.

However, there's more to Reed-Solomon coding than what's covered in that single article: instead
of traditional integer math, a real system will use operation within a Galois Field. And even though 
all Reed-Solomon coding techniques are based on the same idea, there are subtle theoretical variations.
There's also the matter of implementing things in software or hardware. The topic is huge, and there's
probably still research on-going.

My common disclaimer applies: I'm writing these blog posts primarily for myself, as a way to solidify
what I've learned after reading stuff on the web. 

# Something about Polynomials 

It's impossible to discuss anything that's related to coding without touching the subject of polynomials.
I'm assume that you've learned about integer based polynomials during some algebra class in high school
or in college. A polynomial f(x) of degree n is a function that looks like this:

f(x) = c0 + c1 x + c2 x^2 + ... + cn x^n

n+1 fixed coefficients ci are multiplied by input variable x to the power of i. A polynomial is
evaluated by replacing x by some number for which you want to know the value of the function.

In addition to evaluation, you can add polynomial functions together by adding together the coefficients
for each power of x.

f(x) = c0 + c1 x + c2 x^2 + ... + cn x^n
g(x) = d0 + c1 x + d2 x^2 + ... + dn x^n

f(x) + g(x) = (c0 + d0) + (c1 + d1) x + (c2 + d2) x^2 ... + (cn + dn) x^n 

You can multiply polynomials together:

f(x) * g(x) = 
	  cn d0 x^(n+1) 	cn-1 d0    ...   c2 d0 x^2 	 c1 d0 x	  c0 d0	
cn d0 	cn-1 d0    ...             c2 d0         c1 d0           c0 d0	
		
And you can divide them:

...


Encoding methods:

* Original view: codeword as a sequence of values
    * simple encoding procedure: messages as a sequence of coefficients
    * systematic encoding procedure: message as an initial sequence of values
    * dicrete Fourier transform and its inverse
* BCH view: codeword as a sequence of coefficients
    * systematic encoding procedure

# Original Paper

* A code maps from vector space of dimension m over a finite field K (Vm(K)) to a vector
  space of a higher dimension Vn(K) with n>m. K is usually the field of 2 elements Z2.

  In this case, it's essentially a mapping of m bits to n bits.

* n-m bits are redundant, but allow to recover the original message m in case some of the
  n bits are transmitted in error.

* There exists codes with a decoding procedure so that the original message
  can be completely recovered as long a the number of error bits is smaller or equal
  than a number s, where s depends on n and m.

  A Hamming code is an example of such a code.

* Let K be a field of degree n over the field Z2, then K contains 2^n elements. 
  The multiplicative group of K is cyclic, and generated by power of alpha, where alpha
  is the root of an irreducible polynomial over Z2.

* The code E maps m-tuples of K into 2^n tuples of K.

* Let's consider a polynomial P(x) of degree m-1:

	P(x) = a0 + a1 x + a2 x^2 ... + am-1 x^(m-1)

   The coefficients are elements of field K and m < 2^n.

* The code E maps (a0, a1, ..., am-1) to 2^n tuple (P(0), P(alpha), ... , p(1))

    You convert from an m-tuple to an 2^n tuple, and you fill in each of the elements
    of field K into the polynomial and evaluate the result.

* This n-tuple can correct (2^n-m)/2 or (2^n-m-1)/2 symbols, depending on whether m is
  even or odd.

* E maps message of n * m bits to n * 2^n bits.

* The binary representation of code E usually allows the correction of more than (2^n-m-1)/2
  bits, because *all* the bits within a full symbol can be wrong, and a single symbol consists of n bits...
  Because of this, this code is particularly good at correcting errors that are strongly correlated or
  occur in bursts.

* Code E can be generalized to polynomials of the mth degree in several variables over K. When K=Z2,
  such codes reduce to Reed-Muller codes.

	XXX What does this mean?


In the original paper, input (a0, ..., am-1) is used as the polynomial. The polynomial is then
evaluated for all elements of the field. The result of this evaluation is NOT the same as the 
inputs a0 to am-1! So you need to figure out (a0, am-1) by solving m of the 2^n equations:
you take m of the received values and their corresponding field input value, then solve it.

If there were no errors, no matter which of the m received values you used will result in the
same results (a0...am-1).

If there were errors, then there won't be unanimity. As long as there weren't too many errors,
however, the correct value is the result that is most common.




# References

* [Introduction to Reed-Solomon](https://innovation.vivint.com/introduction-to-reed-solomon-bc264d0794f8)

    Very good explanation on polynomial based interpolation and error correction.

    * [Joseph Louis Lagrange and the Polynomials](https://medium.com/@jtolds/joseph-louis-lagrange-and-the-polynomials-499cf0742b39)

	Side story about Lagrange interpolation.

    * [infectious - RS implementation](https://pkg.go.dev/github.com/vivint/infectious)

        Code that goes with the RS article.

* [NASA - Tutorial on Reed-Solomon error correction coding](https://ntrs.nasa.gov/citations/19900019023)

    * [Actual PDF file](https://ntrs.nasa.gov/api/citations/19900019023/downloads/19900019023.pdf)

* [Reed-Solomon on Wikipedia](https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction)

* [Original paper: Polynomial Codes over Certain Finite Fields](https://faculty.math.illinois.edu/~duursma/CT/RS-1960.pdf)

    Only 4 pages!

