---
layout: post
title: SweRV
date:   2019-03-12 17:00:00 -0700
categories:
---


# Notes

Presentation URL: https://wdc.webex.com/wdc/lsr.php?RCID=221a4a6d8d1e4d9c89ba1c501c972502

Starts at 53:30.

Zvonimir Bandic - Western Digital

* 9 stages
* 4 stall points
* Super scalar pipeline boosts performance by 25 up to 30%. Definitely not 100%.
* Instructions can be executed in EX1 or later in EX4.
* If 2 registers are already available, then execute in EX1.
* However if arithmetic instructions has a load dependency, usually this results in a stall. However, here there
  is a second set of second chances: possible to execute the arith instruction when result comes back from
  load pipeline and keep pipeline full.
* This gives you a 50% performance on a single thread!!!
* Only 1 load/store pipeline. Going with two would require a lot of extra resources and power. Too much for an
  embedded core. 1 is reasonable trade-off.
* Divide is 34 cycles, but that's a pessimistic number. It's actually better than that in many cases. Typically
  around 15 to 17 cycles of latency.
* The core focuses a lot of single threaded performance because that's very important for embedded use cases.
  2 classical pipelines would be less area that this core, with better aggregate performance. But lots of
  single threaded legacy code. Also, some code is split between proprietary code and customer code which is hard
  to split.
* pipeline diagram: green means successfully executed.
* A4 depends on L2, but by the time it reaches EX4, the L2 value is there.
    XXX: Is this really true? Hasn't L2 already passed?
* Small out-of-order capability: a slow load that is not referenced doesn't stall the pipe until the point where it 
  is needed.
* Branch prediction: limited choices. Majority of open source cores (Berkeley, ETH Zurich) or commerical cores all
  implement GSHARE algorithm, so you can't do less than that. But GSHARE is also the most complicated that is not
  unreasonably expensive to implement. Well described in the literature by Patterson. Configurable number of
  entries depending on need.
* Branch prediction penalty depends on whether it's in the EX1 (4 cycles) or EX4 (7 cycles). This is the compromise
  of having a secondary ALU.
* Instruction Set Simulator: used for design verification to verify internal state of RTL. Generates traces. Can
  easily be modified for other cores.
  Why not Spike? Because they couldn't figure out how to change Spike for their needs. Lots of experience in the
  team writing ISS. The initial work on this ISS was maybe 7 days of work.
* Physical design: target for the projects was 0.18mm2. End result is well below that.
  ARF: register file. Caches not included in physical design.
* CoreMark: currently at 5.0 (was 4.9) Going higher requires significant investment in terms of logic, branch
  predicition. Normalized numbers, divided by number of cores and threads and frequency. Getting above 7 is
  super hard.
* No instruction fusing. Doesn't fit their ideology.
* Cache line size: 64 bytes.
* Maturity of the tool chain: spend a lot of effort on this. For embedded, compressed is very important. 
  How does it compare to other ISAs?
  Very important that code fits in closely couple memory. Legacy code that used to fit in on-chip RAM should
  still fit in on-chip RAM for RISC-V. E.g. once you exceed 64KB, you have a step function in terms of adding
  extra RAM blocks -> cost.
* Current GCC: only does compression at the assembly level, not earlier, as an opportunistic pass. Doesn't
  exploit all possibilities.
* RISC-V workgroup started and samples of code shared to improve things.
* 8% to 12% larger that other architectures for which GCC already optimizes directly to smaller instructions.
  They are working on improving GCC. Working with partners.
* Various GCC options to improve code density. 
    -lto: debugger doesn't work well
    -msave-restore
    -fno-unroll-loops
  Best result: ~51K. Other ISAs around 51K without LTO, not using GCC. Currently LLVM has much bigger code size.
  There is no SweRV scheduler model in GCC.
* Internal architecture for a NAND controller.
* Use cases where adding compute to the storage side to bypass slow increase in interface bandwidth.

Presentation stops at 1:37

Insteresting presentation:
* http://inst.eecs.berkeley.edu/~cs152/sp18/
* http://inst.eecs.berkeley.edu/~cs152/sp18/lectures/L13-VLIW.pdf
